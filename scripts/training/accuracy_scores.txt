This folder contains all the algorithms that we will test, kindly update this file with the accuracy of the models


Support Vector Machine Classification -> accuracy = 98.28, dataset = spam.csv
                                      -> accuracy = 92.24, dataset = spambase.data
Naive Bayes Classification            -> accuracy = 94.85, dataset = spam.csv
                                      -> accuracy = 78.48, dataset = spambase.data
Logistic Regression Classification    -> accuracy = 98.73, dataset = spam.csv
                                      -> accuracy = 93.62, dataset = spambase.data

Metrics for Phishing_email.csv

SVM     -> no pre  -> accuracy  -> 96.11, 82.62, 82.23, 82.41, 82.89
                      precision -> 93.57, 94.76, 96.54, 95.47, 95.90
                      recall    -> 96.81, 58.21, 57.37, 57.15, 58.61
                      roc_auc   -> 96.23, 78.09, 78.01, 77.72, 78.50
           preproc -> accuracy  -> 96.15, 96.43, 96.17, 96.59, 96.81
                      precision -> 93.77, 94.02, 93.62, 94.40, 94.25
                      recall    -> 96.68, 96.92, 96.96, 96.92, 97.77
                      roc_auc   -> 96.24, 96.52, 96.30, 96.65, 96.98

N B     -> no pre  -> accuracy  -> 96.49, 96.34, 97.39, 95.90, 96.29
                      precision -> 93.47, 93.28, 96.03, 92.02, 92.67
                      recall    -> 97.93, 97.74, 97.15, 97.89, 98.33
                      roc_auc   -> 96.74, 96.59, 97.34, 96.27, 96.65
           preproc -> accuracy  -> 97.18, 97.39, 97.30, 96.79, 97.11
                      precision -> 95.74, 96.12, 95.81, 94.64, 95.39
                      recall    -> 97.17, 97.29, 97.15, 97.20, 97.33
                      roc_auc   -> 97.18, 97.37, 97.27, 96.86, 97.15

Log Reg -> no pre  -> accuracy  -> 96.95, 96.68, 96.72, 97.05, 96.95
                      precision -> 94.57, 94.12, 94.51, 94.83, 94.83
                      recall    -> 97.70, 97.59, 97.22, 97.89, 97.63
                      roc_auc   -> 97.09, 96.84, 96.81, 97.20, 97.06
           preproc -> accuracy  -> 96.40, 96.52, 96.73, 96.45, 96.59
                      precision -> 94.62, 93.91, 94.63, 94.87, 94.98
                      recall    -> 96.14, 97.41, 97.13, 96.23, 96.51
                      roc_auc   -> 96.35, 96.68, 96.81, 96.41, 96.58

Voting  -> no pre  -> accuracy  -> 96.92, 97.50, 97.12, 97.32, 97.50
                      precision -> 95.30, 96.01, 95.25, 95.29, 96.22
                      recall    -> 97.08, 97.65, 97.61, 97.88, 97.52
                      roc_auc   -> 96.94, 97.53, 97.20, 97.42, 97.50
           preproc -> accuracy  -> 98.40, 98.67, 98.28, 98.57, 98.82
                      precision -> 96.72, 97.04, 96.23, 96.69, 97.21
                      recall    -> 99.38, 99.62, 99.58, 99.70, 99.87
                      roc_auc   -> 98.56, 98.84, 98.50, 98.78, 99.00